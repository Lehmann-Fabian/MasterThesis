{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "np.set_printoptions(suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "plt.rcParams['figure.figsize'] = [8,5]\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from matplotlib.ticker import StrMethodFormatter, NullFormatter\n",
    "import dictdiffer\n",
    "\n",
    "from tqdm.notebook import tnrange as nrange\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_pandas_display_options() -> None:\n",
    "    \"\"\"Set pandas display options.\"\"\"\n",
    "    # Ref: https://stackoverflow.com/a/52432757/\n",
    "    display = pandas.options.display\n",
    "\n",
    "    display.max_columns = 1000\n",
    "    display.max_rows = 100\n",
    "    display.max_colwidth = 199\n",
    "    display.width = None\n",
    "    display.float_format = '{:.2f}'.format\n",
    "    # display.precision = 2  # set as needed\n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\Studium\\\\10_Semester\\\\Masterarbeit\\\\Deployment\\\\Kafka\\\\results\\\\setup\"\n",
    "output = \"E:\\\\Studium\\\\10_Semester\\\\Masterarbeit\\\\Deployment\\\\Kafka\\\\eval\\\\\"\n",
    "experiment = 0\n",
    "path = path + str(experiment) + os.path.sep\n",
    "output = output + str(experiment) + os.path.sep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropFirstXRows(input, x):\n",
    "    return input.drop(np.arange(0,x))\n",
    "\n",
    "def removeNaN(array, array2):\n",
    "    helper = np.logical_not(np.isnan(array))\n",
    "    return array[helper], array2[helper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterLastData(generated, received):\n",
    "    lastOffset = received[\"Kafka.Offset\"].to_numpy()[-1]\n",
    "    return generated[generated[\"Kafka.Offset\"] <= lastOffset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    \n",
    "    names = []\n",
    "    produced_generated = []\n",
    "    produced_recieved = []\n",
    "    filtered = []\n",
    "    warnings = []\n",
    "    modelchange = []\n",
    "    firstTimestamp = []\n",
    "    \n",
    "    runs = [x for x in os.listdir(path)]\n",
    "    producerByRun = []\n",
    "    for r in runs:\n",
    "        pathHelper = path + r + str(os.path.sep) + \"data\" + str(os.path.sep)\n",
    "        producer = [pathHelper + x + str(os.path.sep) for x in os.listdir(pathHelper)]\n",
    "        producerByRun.append(producer)\n",
    "\n",
    "        for prod in tqdm(producer):\n",
    "            #print(prod)\n",
    "            time = os.listdir(prod)[0]\n",
    "            topic = list(filter(lambda x : len(x) == 6, os.listdir(prod + time + str(os.path.sep))))[0][:-4]\n",
    "            \n",
    "            dataPath = prod  + str(os.path.sep) + time + str(os.path.sep) + topic\n",
    "            \n",
    "            produced_generated_df = pandas.read_csv(dataPath + \"_produced.csv\")\n",
    "            produced_recieved_df = pandas.read_csv(dataPath + \".csv\")\n",
    "\n",
    "            produced_generated_df = filterLastData(produced_generated_df, produced_recieved_df)\n",
    "\n",
    "            filtered_df = pandas.read_csv(dataPath + \"_filtered.csv\")\n",
    "            warnings_df = pandas.read_csv(dataPath + \"_warnings.csv\")\n",
    "            modelchange_df = pandas.read_csv(dataPath + \"_modelchange.csv\")     \n",
    "            \n",
    "            #remove first 60100 elements ( around 5 minutes)\n",
    "            \n",
    "            modelchange_df = modelchange_df[modelchange_df[\"producedElements\"] > 60101]\n",
    "            \n",
    "            producedFilter = produced_generated_df[\"ProducedElements\"] <= 60100 # last point of anomaly\n",
    "                       \n",
    "            offsets = produced_generated_df[producedFilter][\"Kafka.Offset\"].to_numpy()\n",
    "            produced_generated_df = produced_generated_df[np.logical_not(producedFilter)]\n",
    "\n",
    "            producedReceivedFilter = np.isin(produced_recieved_df[\"Kafka.Offset\"].to_numpy(), offsets)\n",
    "            produced_recieved_df = produced_recieved_df[np.logical_not(producedReceivedFilter)]\n",
    "            \n",
    "            filteredFilter = np.isin(filtered_df[\"Data.Offset\"].to_numpy(), offsets)\n",
    "            offsets = filtered_df[\"Kafka.Offset\"][filteredFilter].to_numpy()\n",
    "            filtered_df = filtered_df[np.logical_not(filteredFilter)]\n",
    "            \n",
    "            warningFilter = np.isin(warnings_df[\"Record.BeginOffset\"], offsets)\n",
    "            warnings_df = warnings_df[np.logical_not(warningFilter)]\n",
    "            \n",
    "            firstTimestampValue = produced_generated_df.iloc()[0][3]\n",
    "            \n",
    "            produced_generated.append(produced_generated_df)\n",
    "            produced_recieved.append(produced_recieved_df)\n",
    "            filtered.append(filtered_df)\n",
    "            warnings.append(warnings_df)\n",
    "            modelchange.append(modelchange_df)\n",
    "            firstTimestamp.append(firstTimestampValue)\n",
    "            \n",
    "            names.append(\"run_\" + r + \"_\" + topic)\n",
    "\n",
    "    return names, produced_generated, produced_recieved, filtered, warnings, modelchange, firstTimestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f06870b9c349b09b4f2015f209e9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2ba93b697f4818bf91e4f9033595c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e66b59abe3741d1827f4bea4001e050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "names, produced_generated, produced_recieved, filtered, warnings, modelchange, firstTimestamp = loadData(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDistribution(data, timestamps = None, path = None, firstTimestamp = None):\n",
    "    \n",
    "    if timestamps is not None:\n",
    "        plt.plot((timestamps - firstTimestamp) / 60000, data)\n",
    "        plt.xlabel(\"time in min\")\n",
    "        plt.ylabel(\"duration in ms\")\n",
    "        plt.savefig(path + \"_over_time.pdf\")\n",
    "        plt.savefig(path + \"_over_time.jpg\", dpi = 300)\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    sorted = np.sort(data)\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "    plt.plot(sorted,np.linspace(0, 1,len(sorted),endpoint=True))\n",
    "    plt.xlabel(\"duration in ms\")\n",
    "    plt.ylabel(\"cumulative frequency\")\n",
    "    \n",
    "    \n",
    "    ax.xaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))\n",
    "    ax.xaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "    if(path is not None):\n",
    "        plt.savefig(path + \"_dist.pdf\")\n",
    "        plt.savefig(path + \"_dist.jpg\", dpi = 300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAvgMedStdMinMaxFromArray(diff, timestamps, path, name, firstTimestamp):\n",
    "    plotDistribution(diff, timestamps, path + name, firstTimestamp)\n",
    "    avg, med, std, minimum, maximum, per90, per95, per99, per99 = (np.average(diff), np.median(diff), np.std(diff), np.min(diff), np.max(diff), np.percentile(diff, 90), np.percentile(diff, 95), np.percentile(diff, 99), np.percentile(diff, 99.9))\n",
    "    datas = [str(x) for x in [name,avg, med, std, minimum, maximum, per90, per95, per99, per99]]\n",
    "    file_object = open(path + 'values.csv', 'a')\n",
    "    file_object.write(\";\".join(datas) + '\\n')\n",
    "    file_object.close()\n",
    "    #return \"avg = %.2f ms; median %.2f ms; std %.2f ms; min %d ms; max %d ms; 90%% %.2f ms; 95%% %.2f ms; 99%% %.2f ms; 99.9%% %.2f ms\"\\\n",
    "    #    %(**datas)\n",
    "    \n",
    "def extractAvgMedStdMinMaxFromListOfArray(inputList,path,unit = \"ms\"):\n",
    "    diff = np.concatenate(inputList, axis = 0)\n",
    "    plotDistribution(diff, path = path)\n",
    "    datas = (np.average(diff), np.median(diff), np.std(diff), np.min(diff), np.max(diff), np.percentile(diff, 90), np.percentile(diff, 95), np.percentile(diff, 99), np.percentile(diff, 99.9))\n",
    "    text = \"avg = %.2f \" + unit + \"; median %.2f \" + unit + \"; std %.2f \" + unit + \"; min %d \" + unit + \"; max %d \" + unit + \"; 90%% %.2f \" + unit + \"; 95%% %.2f \" + unit + \"; 99%% %.2f \" + unit + \"; 99.9%% %.2f \" + unit\n",
    "    print(text %(datas))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDictory(path):\n",
    "    shutil.rmtree(path,ignore_errors=True)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    file_object = open(path + 'values.csv', 'w')\n",
    "    file_object.write(\";\".join([\"name\", \"avg\", \"med\", \"std\", \"minimum\", \"maximum\", \"per90\", \"per95\", \"per99\", \"per99\"]) + '\\n')\n",
    "    file_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of generated data over time\n",
    "\n",
    "consumer & produducer timestamp of the produced data\n",
    "\n",
    "data isn't produced every 5ms instead there are peaks and lows, just the avg is 5ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7219b789b64f4fbb07ad60b56c5b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-557cceb29125>:21: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(p + \".pdf\")\n",
      "<ipython-input-39-557cceb29125>:21: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(p + \".pdf\")\n",
      "<ipython-input-39-557cceb29125>:22: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(p + \".jpg\", dpi = 300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_0_t1\n",
      "run_0_t4\n",
      "run_0_t6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-557cceb29125>:21: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(p + \".pdf\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_0_t5\n",
      "run_0_t3\n",
      "run_0_t2\n",
      "run_0_t7\n",
      "run_1_t6\n",
      "run_1_t1\n",
      "run_1_t3\n",
      "run_1_t7\n",
      "run_1_t2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-557cceb29125>:21: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(p + \".pdf\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1_t5\n",
      "run_1_t4\n",
      "run_2_t4\n",
      "run_2_t7\n",
      "run_2_t6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-557cceb29125>:21: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(p + \".pdf\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_2_t5\n",
      "run_2_t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-557cceb29125>:21: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(p + \".pdf\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_2_t2\n",
      "run_2_t3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def plotHist(data, label, firstTimestamp, width = 250, slabel = False):\n",
    "    timespan = data[-1] - data[0]\n",
    "    \n",
    "    plt.hist((data - firstTimestamp) / 1000, bins = int(timespan / width),zorder=2, label = label)\n",
    "    plt.hlines(width / 5, 0, (data[-1] - firstTimestamp) / 1000, color = \"red\", zorder=1, label = \"expected amount of points\" if slabel else None)\n",
    "    #plt.title(\"Gaussian Histogram\")\n",
    "    plt.xlabel(\"runtime of the experiment in s\")\n",
    "    plt.ylabel(\"data points in an 250 ms intervall\")\n",
    "    plt.legend()\n",
    "\n",
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        producedTime = produced_generated[x].to_numpy()[:,3]\n",
    "        #print(\"Produced data distribution\")\n",
    "        plotHist(producedTime, \"produced data points\", firstTimestamp[x], slabel = True) \n",
    "        #print(\"Recieved produced data distribution\")\n",
    "        plotHist(produced_recieved[x].to_numpy()[:,0], \"recieved data points\", firstTimestamp[x])\n",
    "        p = output + \"produced_hist\" + os.path.sep\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "        p += names[x]\n",
    "        plt.savefig(p + \".pdf\")\n",
    "        plt.savefig(p + \".jpg\", dpi = 300)\n",
    "        plt.close()\n",
    "        print(names[x])\n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How often aggregates Kafka data for produced_recieved\n",
      "Modus: 2 with 19.13%\n",
      "One element with 15.11%\n",
      "avg = 8.95 r/s; median 3.00 r/s; std 14.95 r/s; min 1 r/s; max 295 r/s; 90% 39.00 r/s; 95% 46.00 r/s; 99% 56.00 r/s; 99.9% 95.00 r/s\n"
     ]
    }
   ],
   "source": [
    "def kafkaAggCount(dataList, index, label, path):\n",
    "    print(\"How often aggregates Kafka data for\", label)\n",
    "    counts = []\n",
    "    for x in range(len(names)):\n",
    "       counts.append(np.unique(produced_recieved[x].to_numpy()[:,index], return_counts = True)[1])\n",
    "    a,b = np.unique(np.concatenate(counts, axis = 0), return_counts=True)\n",
    "    countsSum = np.sum(b)\n",
    "    np.max(b)\n",
    "    print(\"Modus: %d with %.2f%%\" %(a[np.where(b == np.max(b))][0], (np.max(b) / countsSum) * 100))\n",
    "    print(\"One element with %.2f%%\" %((b[np.where(a == 1)][0] / countsSum) * 100))\n",
    "    extractAvgMedStdMinMaxFromListOfArray(counts, path, \"r/s\")\n",
    "\n",
    "kafkaAggCount(produced_recieved, 0, \"produced_recieved\", output + \"produced_records_sub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information on the time difference between the arival time of records for all 3 topics\n",
    "\n",
    "peaks caused by cpu time, it is not regulary produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33350fd107964c5dac5d2aa90143e090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arival diff of generated data\n",
      "avg = 5.00 ms; median 5.00 ms; std 3.38 ms; min 0 ms; max 657 ms; 90% 6.00 ms; 95% 7.00 ms; 99% 11.00 ms; 99.9% 23.00 ms\n",
      "Percentage of 5ms 57.07\n",
      "Percentage of 0ms 2.64\n",
      "Percentage of <=10ms 98.93\n",
      "Percentage of >100ms 0.01\n",
      "\n",
      "Arival diff of generated data from Kafka\n",
      "avg = 5.00 ms; median 0.00 ms; std 28.18 ms; min 0 ms; max 1488 ms; 90% 8.00 ms; 95% 19.00 ms; 99% 206.00 ms; 99.9% 266.00 ms\n",
      "Arival diff of filtered data from Kafka\n",
      "avg = 5.00 ms; median 0.00 ms; std 33.83 ms; min 0 ms; max 1831 ms; 90% 0.00 ms; 95% 12.00 ms; 99% 221.00 ms; 99.9% 433.00 ms\n",
      "Arival diff of warning data from Kafka\n",
      "avg = 26.76 ms; median 0.00 ms; std 73.12 ms; min 0 ms; max 1456 ms; 90% 54.00 ms; 95% 224.00 ms; 99% 350.00 ms; 99.9% 606.50 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24, 25,  0, ...,  0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avgMedStdArivalTime(df, column, path, name, firstTimestamp, filterArray = None):\n",
    "    df = df.to_numpy()[:,column].astype(np.int64)\n",
    "    diff = df[1:,]-df[:-1,]\n",
    "    timestamps = df[1:,]\n",
    "    if filterArray is not None:\n",
    "        diff = diff[filterArray]\n",
    "        timestamps = timestamps[filterArray]\n",
    "    extractAvgMedStdMinMaxFromArray(diff, timestamps, path, name, firstTimestamp)\n",
    "    return diff\n",
    "    \n",
    "\n",
    "currentPath = output + \"arivalTimesOfData\" + os.path.sep\n",
    "shutil.rmtree(currentPath,ignore_errors=True)\n",
    "pathesWithoutSep = [currentPath + \"produced_generated\", currentPath + \"produced_received\", currentPath + \"filtered\", currentPath + \"warnings\"] \n",
    "pathes = [x + os.path.sep for x in pathesWithoutSep]\n",
    "for x in pathes:\n",
    "    prepareDictory(x)\n",
    "    \n",
    "pro_gen = []\n",
    "pro_rec = []\n",
    "fil = []\n",
    "war = []\n",
    "    \n",
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        pro_gen.append(avgMedStdArivalTime(produced_generated[x], 3,pathes[0] + os.path.sep, names[x], firstTimestamp[x]))\n",
    "        pro_rec.append(avgMedStdArivalTime(produced_recieved[x], 0, pathes[1] + os.path.sep, names[x], firstTimestamp[x]))\n",
    "        fil.append(avgMedStdArivalTime(filtered[x], 0, pathes[2] + os.path.sep, names[x], firstTimestamp[x]))\n",
    "        warningFilter = np.logical_not(np.isin(warnings[x][\"Record.BeginOffset\"].to_numpy(), modelchange[x][\"producedElements\"].to_numpy())[1:])\n",
    "        war.append(avgMedStdArivalTime(warnings[x], 0, pathes[3] + os.path.sep, names[x], firstTimestamp[x], warningFilter))\n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)\n",
    "\n",
    "print(\"Arival diff of generated data\")\n",
    "diff = extractAvgMedStdMinMaxFromListOfArray(pro_gen, pathesWithoutSep[0])\n",
    "print(\"Percentage of 5ms %.2f\" %((np.sum(diff == 5)/len(diff) * 100)))\n",
    "print(\"Percentage of 0ms %.2f\" %((np.sum(diff == 0)/len(diff) * 100)))\n",
    "print(\"Percentage of <=10ms %.2f\" %((np.sum(diff <= 10)/len(diff) * 100)))\n",
    "print(\"Percentage of >100ms %.2f\" %((np.sum(diff > 100)/len(diff) * 100)))\n",
    "print()\n",
    "print(\"Arival diff of generated data from Kafka\")\n",
    "extractAvgMedStdMinMaxFromListOfArray(pro_rec, pathesWithoutSep[1])\n",
    "print(\"Arival diff of filtered data from Kafka\")\n",
    "extractAvgMedStdMinMaxFromListOfArray(fil, pathesWithoutSep[2])\n",
    "print(\"Arival diff of warning data from Kafka\")\n",
    "_ = extractAvgMedStdMinMaxFromListOfArray(war, pathesWithoutSep[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of 5ms 57.07\n",
      "Percentage of 0ms 2.64\n",
      "Percentage of <=10ms 98.93\n",
      "Percentage of >100ms 0.01\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of 5ms %.2f\" %((np.sum(diff == 5)/len(diff) * 100)))\n",
    "print(\"Percentage of 0ms %.2f\" %((np.sum(diff == 0)/len(diff) * 100)))\n",
    "print(\"Percentage of <=10ms %.2f\" %((np.sum(diff <= 10)/len(diff) * 100)))\n",
    "print(\"Percentage of >100ms %.2f\" %((np.sum(diff > 100)/len(diff) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Produced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long does it take until a produced record is acknowledged by kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58802d981bc5457aa94ea771479800c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Produced acknowledged by Kafka\n",
      "avg = 166.59 ms; median 151.00 ms; std 119.19 ms; min 1 ms; max 1693 ms; 90% 295.00 ms; 95% 396.00 ms; 99% 515.00 ms; 99.9% 845.00 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 99,  93,  87, ..., 236, 231, 349], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kafkaAck(df, path, name, firstTimestamp):\n",
    "    ack = df.to_numpy()[:,0].astype(np.int64)\n",
    "    send = df.to_numpy()[:,3].astype(np.int64)\n",
    "    diff = ack - send\n",
    "    extractAvgMedStdMinMaxFromArray(diff, send, path, name, firstTimestamp)\n",
    "    return diff\n",
    "\n",
    "\n",
    "currentPath = output + \"producedAckByKafka\"\n",
    "prepareDictory(currentPath + os.path.sep)\n",
    "\n",
    "kaf = []\n",
    "\n",
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        kaf.append(kafkaAck(produced_recieved[x], currentPath + os.path.sep, names[x], firstTimestamp[x]))\n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)\n",
    "\n",
    "print(\"Produced acknowledged by Kafka\")\n",
    "_ = extractAvgMedStdMinMaxFromListOfArray(kaf, currentPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check validity of produced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc61cd6d095449f0a7d6fa641cea07fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def validate(df, heigherFields, heigherOrEqualFields, offset):\n",
    "    df = df.to_numpy()#[:,0:4]\n",
    "    \n",
    "    lastRow = df[0]\n",
    "    error = False\n",
    "    \n",
    "    for x in df[1:]:\n",
    "            \n",
    "        if(np.sum(x[heigherFields] > lastRow[heigherFields]) != len(heigherFields) or \n",
    "           np.sum(x[heigherOrEqualFields] >= lastRow[heigherOrEqualFields]) != len(heigherOrEqualFields)):\n",
    "            error = True\n",
    "            print(\"Error:\")\n",
    "            print(lastRow)\n",
    "            print(x)\n",
    "        if(not np.sum(lastRow[offset] + 1 == x[offset]) == len(offset)):\n",
    "            print(\"Offset %i increased not by 1\" %lastRow[2])\n",
    "            \n",
    "        lastRow = x\n",
    "    return not error\n",
    "        \n",
    "    #f.value = 100\n",
    "\n",
    "for x in nrange(len(names)):\n",
    "    if not validate(produced_recieved[x],[2],[0,1,3],[2]):\n",
    "        print(\"Not valid produced\", names[x])\n",
    "    if not validate(filtered[x],[2,3],[0,1,4],[2,3]):\n",
    "        print(\"Not valid filtered\", names[x])\n",
    "    if not validate(warnings[x],[2,4,5],[0,1,6,7],[2]):\n",
    "        print(\"Not valid warnings\", names[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time between the last step and the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c12a35ae1934ef683c555bf04cb371f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Produced -> Produced Received\n",
      "avg = 166.55 ms; median 151.00 ms; std 119.19 ms; min 1 ms; max 1693 ms; 90% 295.00 ms; 95% 396.00 ms; 99% 515.00 ms; 99.9% 845.00 ms\n",
      "More than 100 ms: 112255.90%\n",
      "Produced -> Filtered\n",
      "avg = 178.22 ms; median 155.00 ms; std 161.56 ms; min -1279 ms; max 2277 ms; 90% 365.00 ms; 95% 468.00 ms; 99% 670.00 ms; 99.9% 1171.00 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([254, 254, 254, ..., 161, 161, 161], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractDiffBetweenTwoTables(a,b,keyA,keyB, sortBy, valueA, valueB):\n",
    "    joined = a.set_index(keyA).add_prefix('a_').join(b.set_index(keyB).add_prefix('b_'))#.sort_values(\"b_\" + sortBy, ascending = True)\n",
    "\n",
    "    diff = joined['a_' + valueA].to_numpy() - joined['b_' + valueB].to_numpy()\n",
    "    return diff, joined['b_' + valueB].to_numpy(), joined\n",
    "\n",
    "currentPathPF = output + \"receivedByFollowingTopic\" + os.path.sep + \"ProducedFiltered\"\n",
    "prepareDictory(currentPathPF + os.path.sep)\n",
    "currentPathPPR = output + \"receivedByFollowingTopic\" + os.path.sep + \"ProducedProdRec\"\n",
    "prepareDictory(currentPathPPR + os.path.sep)\n",
    "\n",
    "diffListPF = []\n",
    "diffListPPR = []\n",
    "\n",
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        diffPF, timestamps, _ = extractDiffBetweenTwoTables(filtered[x], produced_recieved[x], 'Data.Offset', 'Kafka.Offset', \"Consumer.Time\", 'Consumer.Time', 'Consumer.Time')\n",
    "        extractAvgMedStdMinMaxFromArray(diffPF, timestamps, currentPathPF + os.path.sep, names[x], firstTimestamp[x])\n",
    "        diffListPF.append(diffPF)\n",
    "        \n",
    "        diffPPR, timestamps, _ = extractDiffBetweenTwoTables(produced_recieved[x], produced_generated[x], 'Kafka.Offset', 'Kafka.Offset', \"Kafka.Offset\", 'Consumer.Time', 'Producer.Timestamp')\n",
    "        extractAvgMedStdMinMaxFromArray(diffPPR, timestamps, currentPathPPR + os.path.sep, names[x], firstTimestamp[x])\n",
    "        diffListPPR.append(diffPPR)\n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)\n",
    "\n",
    "        \n",
    "print(\"Produced -> Produced Received\")\n",
    "extractAvgMedStdMinMaxFromListOfArray(diffListPPR, currentPathPPR)\n",
    "diffPPR = np.concatenate(diffListPPR, axis = 0)\n",
    "print(\"More than 100 ms: %.2f%%\"%((np.sum(diffPPR > 100) / len(diffPPR)) * 100))\n",
    "print(\"More lower than 8 ms: %.2f%%\"%((np.sum(diffPPR < 8) / len(diffPPR)) * 100))\n",
    "\n",
    "print(\"Produced -> Filtered\")\n",
    "_ = extractAvgMedStdMinMaxFromListOfArray(diffListPF, currentPathPF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print two together\n",
    "def printTwoTogether(combineIds, namesForIds):\n",
    "\n",
    "    indexes = [names.index(x) for x in combineIds]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "    for x in range(len(indexes)):\n",
    "        diffPPR, timestamps, _ = extractDiffBetweenTwoTables(produced_recieved[indexes[x]], produced_generated[indexes[x]], 'Kafka.Offset', 'Kafka.Offset', \"Kafka.Offset\", 'Consumer.Time', 'Producer.Timestamp')\n",
    "        #extractAvgMedStdMinMaxFromArray(diffPPR, None, None, None, None)\n",
    "        sorted = np.sort(diffPPR)\n",
    "        plt.plot(sorted,np.linspace(0, 1,len(sorted),endpoint=True), label = namesForIds[x])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlabel(\"duration in ms\")\n",
    "    plt.ylabel(\"cumulative frequency\")\n",
    "    plt.legend()\n",
    "\n",
    "    ax.xaxis.set_major_formatter(StrMethodFormatter('{x:.0f}'))\n",
    "    ax.xaxis.set_minor_formatter(NullFormatter())\n",
    "\n",
    "    cOutput = output + \"receivedByFollowingTopic\" + os.path.sep + \"ProducedProdRec_\" + \"-\".join(combineIds)\n",
    "    plt.savefig(cOutput + \".jpg\", dpi = 300)\n",
    "    plt.savefig(cOutput + \".pdf\")\n",
    "    plt.show()\n",
    "\n",
    "printTwoTogether([\"run_2_t1\", \"run_2_t7\"], [\"t1\", \"t7\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative values are possible, a node can receive the warnings before the filtered, it depends on the position in cluster an other aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755fa485467347b58cdc82aedb459250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered -> Warning\n",
      "avg = 1277.20 ms; median 1142.00 ms; std 901.50 ms; min -427 ms; max 8853 ms; 90% 2479.00 ms; 95% 2941.00 ms; 99% 3878.00 ms; 99.9% 5616.51 ms\n",
      "ProducedRec -> Warning\n",
      "avg = 1458.33 ms; median 1325.00 ms; std 909.28 ms; min -244 ms; max 9154 ms; 90% 2666.00 ms; 95% 3126.00 ms; 99% 4117.64 ms; 99.9% 5973.06 ms\n",
      "ProducedGen -> Warning\n",
      "avg = 1626.11 ms; median 1501.00 ms; std 906.62 ms; min 52 ms; max 9164 ms; 90% 2816.00 ms; 95% 3275.00 ms; 99% 4269.66 ms; 99.9% 6088.53 ms\n"
     ]
    }
   ],
   "source": [
    "currentPathFW = output + \"receivedByFollowingTopic\" + os.path.sep + \"FilteredRecWarning\"\n",
    "prepareDictory(currentPathFW + os.path.sep)\n",
    "\n",
    "currentPathPW = output + \"receivedByFollowingTopic\" + os.path.sep + \"ProducedRecWarning\"\n",
    "prepareDictory(currentPathPW + os.path.sep)\n",
    "\n",
    "currentPathPGW = output + \"receivedByFollowingTopic\" + os.path.sep + \"ProducedGenWarning\"\n",
    "prepareDictory(currentPathPGW + os.path.sep)\n",
    "\n",
    "fw = []\n",
    "pw = []\n",
    "pgw = []\n",
    "\n",
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        \n",
    "        #In warnings Record.BeginOffset and Record.EndOffset are the related filtered offsets! There is no guarantee that these values are the same!!\n",
    "        warnings_filtered_joined = warnings[x].set_index(\"Record.BeginOffset\").join(filtered[x].add_prefix('fb_').set_index(\"fb_Kafka.Offset\")).set_index(\"Record.EndOffset\").join(filtered[x].add_prefix('fe_').set_index(\"fe_Kafka.Offset\"))\n",
    "\n",
    "        diff = (warnings_filtered_joined[\"Consumer.Time\"] - warnings_filtered_joined[\"fb_Consumer.Time\"]).to_numpy()\n",
    "        diff, timestamps = removeNaN(diff, warnings_filtered_joined[\"fb_Consumer.Time\"].to_numpy())\n",
    "        extractAvgMedStdMinMaxFromArray(diff, timestamps, currentPathFW + os.path.sep, names[x], firstTimestamp[x])\n",
    "        fw.append(diff)\n",
    "\n",
    "        diff, timestamps, prod_warning_join = extractDiffBetweenTwoTables(warnings_filtered_joined, produced_recieved[x].add_prefix('pr_'), 'fb_Data.Offset', 'pr_Kafka.Offset', \"pr_Consumer.Time\", 'Consumer.Time', 'pr_Consumer.Time')\n",
    "        diff, timestamps = removeNaN(diff, timestamps)\n",
    "        extractAvgMedStdMinMaxFromArray(diff, timestamps, currentPathPW + os.path.sep, names[x], firstTimestamp[x])\n",
    "        pw.append(diff)\n",
    "        \n",
    "        prodGenProdRec = produced_generated[x].set_index(\"Kafka.Offset\").join(produced_recieved[x].set_index(\"Kafka.Offset\")).reset_index()\n",
    "        diff, timestamps, prod_warning_join = extractDiffBetweenTwoTables(warnings_filtered_joined, prodGenProdRec.add_prefix('pr_'), 'fb_Data.Offset', 'pr_Kafka.Offset', \"pr_Consumer.Time\", 'Consumer.Time', 'pr_Producer.Timestamp')\n",
    "        diff, timestamps = removeNaN(diff, timestamps)\n",
    "        extractAvgMedStdMinMaxFromArray(diff, timestamps, currentPathPW + os.path.sep, names[x], firstTimestamp[x])\n",
    "        pgw.append(diff)\n",
    "        \n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)\n",
    "\n",
    "print(\"Filtered -> Warning\")\n",
    "extractAvgMedStdMinMaxFromListOfArray(fw, currentPathFW)\n",
    "print(\"ProducedRec -> Warning\")\n",
    "_ = extractAvgMedStdMinMaxFromListOfArray(pw, currentPathPW)\n",
    "print(\"ProducedGen -> Warning\")\n",
    "_ = extractAvgMedStdMinMaxFromListOfArray(pgw, currentPathPGW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More than 3000 ms: 7.75%\n",
      "More than 5000 ms: 0.32%\n"
     ]
    }
   ],
   "source": [
    "diff = np.concatenate(pgw, axis = 0)\n",
    "print(\"More than 3000 ms: %.2f%%\"%((np.sum(diff > 3000) / len(diff)) * 100))\n",
    "print(\"More than 5000 ms: %.2f%%\"%((np.sum(diff > 5000) / len(diff)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loss produced to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd06c04ebcc43f188d100508045936b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calcDataLoss(df1, df1OffsetColumn, df2, df2OffsetColumn):\n",
    "    df1Offsets = df1.to_numpy()[:,df1OffsetColumn].astype(np.int64)\n",
    "    df2Offsets = df2.to_numpy()[:,df2OffsetColumn].astype(np.int64)\n",
    "    \n",
    "    errors = {}\n",
    "        \n",
    "    count = {}\n",
    "    \n",
    "    for x in df1Offsets:\n",
    "        \n",
    "        count[x] = 0\n",
    "\n",
    "        \n",
    "        #count = np.sum(df2Offsets == x)\n",
    "        \n",
    "        #if(count != 1):\n",
    "        #    errors[count] = errors.get(count, 0) + 1\n",
    "        \n",
    "    for x in df1Offsets:\n",
    "        count[x] = count[x] + 1\n",
    "        \n",
    "    for k, v in count.items():\n",
    "        if v != 1:\n",
    "            errors[count] = errors.get(count, 0) + 1\n",
    "    \n",
    "    out = \"Received records \"\n",
    "    losses = False\n",
    "    for k, v in errors.items():\n",
    "        out += \"%ix for %i times; \" %(k,v)\n",
    "        losses = True\n",
    "    \n",
    "    if(losses):\n",
    "        print(out)\n",
    "    #else:\n",
    "    #    print(\"The expected data was received exactly once.\")\n",
    "    return not losses\n",
    "\n",
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        \n",
    "        if not calcDataLoss(produced_generated[x], 0, filtered[x], 3) :\n",
    "            print(\"Error\", names[x])\n",
    "        \n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency produced - warning\n",
    "\n",
    "As the filter uses a median filter with size 5 it needs 3 outliers to detect a change. otherwise it is just skipped. ==> there must be a latency of at least (3*5ms) = 15ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check all anomalies were detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff657bb1b8fe463981e65534f784e59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "Found 3535 warnings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        \n",
    "        filterOver10 = filtered[x][filtered[x][\"Data.Measurement\"] > 1.0]\n",
    "        filterOver10Joined = filterOver10.add_prefix('filtered_').set_index(\"filtered_Kafka.Offset\").join(warnings[x].add_prefix('warnings_').set_index(\"warnings_Record.BeginOffset\"))\n",
    "        noBelongingWarning = filterOver10Joined[filterOver10Joined[\"warnings_Consumer.Time\"].isna()]\n",
    "        print(\"Found %d warnings\" %(len(filterOver10)))\n",
    "        if(len(noBelongingWarning) > 0):\n",
    "            print(\"%s: For %d / %d anomalies there were no belonging warnings\" %(names[x], len(noBelongingWarning),len(filterOver10)))\n",
    "        \n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c014f5c7a1094c73aa15e9224255cc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to detect an anomaly\n",
      "avg = 495.19 ms; median 462.00 ms; std 225.85 ms; min 96 ms; max 2178 ms; 90% 768.40 ms; 95% 874.50 ms; 99% 1222.46 ms; 99.9% 1785.31 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 663., 1050.,  167.,  494.,  562.,  144.,  538.,  206.,  572.,\n",
       "        340.,  519.,  428.,  276.,  484.,  234.,  193.,  394.,  308.,\n",
       "        299.,  505.,  490., 1008.,  453.,  405.,  334.,  145.,  365.,\n",
       "        527.,  536.,  178.,  175.,  351.,  276.,  599.,  514., 1238.,\n",
       "        524.,  321.,  401.,  527.,  373.,  751.,  773.,  713.,  803.,\n",
       "        792.,  946.,  454.,  641.,  597.,  591.,  773.,  376.,  180.,\n",
       "        808.,  309.,  683.,  595.,  549., 1202.,  461.,  472., 1028.,\n",
       "        786.,  347.,  417.,  601.,  666.,  509.,  476., 1034.,  622.,\n",
       "        636.,  797.,  440.,  304.,  747.,  231., 1319.,  484., 1187.,\n",
       "        941.,  348.,  386.,  374.,  608.,  596.,  285.,  218.,  223.,\n",
       "        351.,  754.,  487.,  468.,  739.,  441.,  320.,  359.,  670.,\n",
       "        377.,  501.,  493.,  584.,  766.,  571.,  744.,  541.,  381.,\n",
       "        419.,  359., 1128., 1233.,  249.,  579.,  446.,  983.,  445.,\n",
       "        742.,  448.,  651.,  467.,  443.,  188.,  590.,  458.,  590.,\n",
       "        732.,  298.,  698.,  336.,  339.,  613.,  549.,  635.,  365.,\n",
       "        543.,  354.,  206.,  401.,  291.,  375.,  426.,  642.,  680.,\n",
       "        776.,  779., 2178.,  329.,  595.,  675.,  873.,  332.,  224.,\n",
       "        763., 1052.,  262.,  645.,  230.,  712.,  363.,  659.,  700.,\n",
       "        741.,  309.,  562.,  284.,  342.,  324.,  867.,  364.,  605.,\n",
       "        563.,  283.,  764.,  643.,  702.,  317.,  202.,  485.,  602.,\n",
       "        453., 1643.,  563.,  601.,  365.,  814.,  438.,  297.,  199.,\n",
       "        470.,  463.,  556.,  335.,  668.,  147.,  520.,  212.,  426.,\n",
       "        153.,  554.,  249.,  465.,  206.,  595.,  303.,  333.,  398.,\n",
       "        498.,  382.,  688.,  376.,  409.,  118.,  405.,  238.,  536.,\n",
       "        505.,  384.,  394.,  570.,  651.,  481.,  352.,  325.,  474.,\n",
       "        343.,  212.,  465.,  137.,  538.,  366.,  165.,  313.,  371.,\n",
       "        257.,  373.,  209.,  127.,  643.,  311.,  576.,  258.,  479.,\n",
       "        373.,  359.,  409.,  561.,  390.,  448.,  690.,  361.,  990.,\n",
       "        626.,  501.,  556.,  195.,  513.,  429.,  814.,  583.,  318.,\n",
       "        161.,  393.,  501.,  321.,  504.,  409.,  267.,  501.,  383.,\n",
       "        256.,  530.,  206.,  586.,  710.,  403.,  402.,  523.,  382.,\n",
       "        478.,  520.,  403.,  424.,  343.,  311.,  441.,  670.,  470.,\n",
       "        451.,  565.,  529.,  412.,  403.,  576.,  172.,  324.,  523.,\n",
       "        308., 1194.,  154.,  594.,  404.,  532.,  423.,  595.,  316.,\n",
       "       1388.,  362.,  174.,  365.,  366.,  310.,  268.,  585.,  464.,\n",
       "        470.,  129.,  723.,  371.,  556.,  316.,  608.,  447.,  447.,\n",
       "        248.,  681.,  604.,  438.,  871.,  344.,  368.,  420.,  362.,\n",
       "        451.,  388.,  400.,  535.,  357.,  573.,  666.,  617.,  214.,\n",
       "        660.,  485.,  367.,  412.,  438.,  762.,  865.,  233.,  536.,\n",
       "        409.,  799.,  420.,  371.,  343.,  687.,  611.,  534.,  464.,\n",
       "        507.,  537.,  326.,  329.,  274.,  545.,  676.,  221.,  334.,\n",
       "        434.,  620.,  664.,  454.,  325.,  519.,  447.,  115.,  424.,\n",
       "        477.,  617.,  659.,  300.,  460.,  648.,  159.,  557.,  363.,\n",
       "        734.,  501.,  382.,  511.,  770.,  510.,  554.,  467.,  881.,\n",
       "        572., 1329.,  938.,  354.,  265.,  567.,  445.,  709.,  869.,\n",
       "        426.,  937.,  221.,  414.,  272.,  485.,  471.,  755.,  718.,\n",
       "        382.,  674.,  867.,  491.,  445.,  245.,  173.,  545.,  267.,\n",
       "        196.,  492.,  615.,  157.,  324.,  631.,  547.,  140.,  186.,\n",
       "        413.,  432.,  467.,  400.,  659.,  316.,  522.,  778.,  313.,\n",
       "        235.,  384.,  321.,  394.,  153.,  213.,  360.,  252.,  359.,\n",
       "        299., 1136.,  335.,  418.,  291.,  368.,  432., 1257.,  576.,\n",
       "        635.,  374.,  543.,  561.,  400.,  850.,  727.,  419.,  359.,\n",
       "        754.,  781.,  846.,  329.,  664.,  570.,  914.,  837.,  459.,\n",
       "        570.,  479., 1081.,  591.,  438.,  196.,  491.,  795.,  424.,\n",
       "        231.,  414.,  438.,  665.,  851.,  678.,  233.,  404.,  546.,\n",
       "        311.,  452.,  836.,  454.,  675.,  466.,  222.,  514.,  226.,\n",
       "        621.,  425.,  791.,  527.,  521.,  668.,  487.,  607.,  502.,\n",
       "        464.,  287.,  286.,  120.,  529.,  415.,  713.,  532.,  406.,\n",
       "        385.,  521.,  375.,  581.,  438.,  443.,  387.,  420.,  147.,\n",
       "        166.,  515.,  144.,  450.,  393.,  567.,  679.,  267.,  608.,\n",
       "        474.,  465.,  578.,  351.,  178.,  395.,  380.,  702.,  193.,\n",
       "        410.,  423.,  120.,  462.,  316.,  242.,  410.,  207.,  489.,\n",
       "        701.,  528.,  495.,  258.,  482.,  194.,   96.,  365.,  394.,\n",
       "        361.,  437.,  378.,  297.,  513.,  412.,  360.,  520.,  576.,\n",
       "        500.,  328.,  176.,  475.,  499.,  353.,  661.,  164.,  390.,\n",
       "        241.,  237.,  239.,  514.,  533.,  627.,  558.,  263.,  229.,\n",
       "        321.,  406.,  256.,  749.,  434.,  781.,  946.,  975.,  448.,\n",
       "        361.,  569.,  234.,  413.,  497.,  452.,  438.,  627.,  504.,\n",
       "        593.,  326.,  968.,  322.,  529.,  352.,  543.,  727.,  490.,\n",
       "        251.,  388.,  373.,  591.,  799.,  740.,  494.,  534.,  827.,\n",
       "        500.,  315.,  407.,  521.,  392.,  561.,  305.,  477.,  466.,\n",
       "        708., 1088., 1148.,  367.,  151.,  225.,  796.,  478.,  693.,\n",
       "        714.,  377., 1180.,  452.,  459.,  445.,  475.,  878., 1127.,\n",
       "        475.,  500.,  359.,  637.,  642.,  642.,  799.,  347.,  796.,\n",
       "        275.,  346.,  436.,  371.,  443.,  303.,  205.,  466.,  198.,\n",
       "        457.,  672.,  341.,  308.,  675.,  591.,  766.,  301.,  448.,\n",
       "        288.,  542.,  550.,  414.,  421.,  465.,  503.,  415.,  644.,\n",
       "        508.,  230.,  349.,  593.,  252.,  444.,  624.,  764.,  572.,\n",
       "        697.,  924.,  564.,  462., 1002.,  388.,  497.,  541.,  655.,\n",
       "        745.,  401.,  693.,  445.,  508.,  444.,  870.,  430.,  458.,\n",
       "        404.,  402.,  467.,  359.,  341.,  648.,  462.,  357.,  770.,\n",
       "        468.,  624.,  479.,  514.,  550.,  836.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentPath = output + \"anomalyDetectionTime\"\n",
    "prepareDictory(currentPath + os.path.sep)\n",
    "\n",
    "diffList = []\n",
    "\n",
    "for x in nrange(len(names)):\n",
    "    try:\n",
    "        \n",
    "        #received and produced\n",
    "        pr_rc = produced_generated[x].add_prefix('produced_generated_').set_index(\"produced_generated_Kafka.Offset\").join(produced_recieved[x].add_prefix('produced_recieved_').set_index(\"produced_recieved_Kafka.Offset\")).reset_index()\n",
    "\n",
    "        #received and produced and filtered\n",
    "        pr_rc_fi = pr_rc.set_index(\"produced_generated_Kafka.Offset\").join(filtered[x].add_prefix('filtered_').set_index(\"filtered_Data.Offset\")).reset_index()\n",
    "\n",
    "        #changes and received and produced and filtered\n",
    "        mc_pg_pr_fi = modelchange[x].add_prefix('modelchange_').set_index(\"modelchange_producedElements\").join(pr_rc_fi.set_index(\"produced_generated_ProducedElements\")).reset_index().rename(columns={'modelchange_producedElements': 'producedElements'})\n",
    "\n",
    "        #merge all with warnings\n",
    "        fullJoin = mc_pg_pr_fi.set_index(\"filtered_Kafka.Offset\").join(warnings[x].add_prefix('warning_').set_index(\"warning_Record.BeginOffset\")).reset_index()\n",
    "\n",
    "        fullJoinOver10 = fullJoin[fullJoin[\"modelchange_value\"] > 1]\n",
    "\n",
    "        diff = (fullJoinOver10['warning_Consumer.Time'] - fullJoinOver10['produced_generated_Producer.Timestamp']).to_numpy()\n",
    "\n",
    "        timestamps = fullJoinOver10['produced_generated_Producer.Timestamp'].to_numpy()\n",
    "\n",
    "        if (np.isnan(diff[-1])):\n",
    "            diff = diff[:-1]\n",
    "            timestamps = timestamps[:-1]\n",
    "\n",
    "\n",
    "        diffList.append(diff)\n",
    "        extractAvgMedStdMinMaxFromArray(diff, timestamps, currentPath + os.path.sep, names[x], firstTimestamp[x])\n",
    "        \n",
    "    except Exception as e:\n",
    "        plt.close()\n",
    "        print(e)\n",
    "        print(\"Error\", names[x], x)\n",
    "\n",
    "print(\"Time to detect an anomaly\")\n",
    "_ = extractAvgMedStdMinMaxFromListOfArray(diffList, currentPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractUsage(lines, server, run):\n",
    "    data = {}\n",
    "\n",
    "    date = None\n",
    "    for l in lines:\n",
    "        if l.startswith(\"Time \"):\n",
    "            date = int(l[5:-1])\n",
    "        else:\n",
    "            e = l.split(' ');\n",
    "            e = list(filter(lambda x: x != \"\", e))\n",
    "            cpu = float(e[0])\n",
    "            mem = float(e[1])\n",
    "            pid = int(e[2])\n",
    "            time = e[3].split(\":\")\n",
    "            secondsRunning = int(time[0]) * 3600 + int(time[1]) * 60 + int(time[2])\n",
    "            name = e[4]\n",
    "            container = e[5]\n",
    "            up = e[6]\n",
    "            \n",
    "            if(name.startswith(\"etcd\")):\n",
    "                pass\n",
    "            else:\n",
    "                split = name.split(\"_\")\n",
    "                \n",
    "                if split[1] == \"POD\":\n",
    "                    continue\n",
    "                name = split[1] + \"-\" +  split[2]\n",
    "            \n",
    "            pid_data = data.get(pid, {\n",
    "                \"mem\": [],\n",
    "                \"cpu\": [],\n",
    "                \"pid\" : pid,\n",
    "                \"running\" : [],\n",
    "                \"name\" : name,\n",
    "                \"container\" : container\n",
    "            })\n",
    "\n",
    "            pid_data[\"mem\"].append(mem)\n",
    "            pid_data[\"cpu\"].append(cpu)\n",
    "            pid_data[\"running\"].append(date)\n",
    "\n",
    "            data[pid] = pid_data\n",
    "\n",
    "    zero_cpu = []\n",
    "    for k in data:\n",
    "        summ = sum(data[k][\"cpu\"])\n",
    "        if summ == 0.0 or data[k][\"name\"].startswith(\"debug\"):\n",
    "            zero_cpu.append(k)\n",
    "\n",
    "    for x in zero_cpu:\n",
    "        del data[x]\n",
    "\n",
    "    outpath = output + \"usage\" + os.path.sep\n",
    "    \n",
    "    outpathMem = outpath + \"mem\" + os.path.sep\n",
    "    outpathCPU = outpath + \"cpu\" + os.path.sep\n",
    "\n",
    "    os.makedirs(outpathMem, exist_ok=True)\n",
    "    os.makedirs(outpathCPU, exist_ok=True)\n",
    "\n",
    "    for k in data:\n",
    "        cpu = data[k][\"cpu\"]\n",
    "        running = data[k][\"running\"]\n",
    "        plt.plot(running, cpu, label = data[k][\"name\"][:40])\n",
    "    plt.legend() \n",
    "    plt.ylabel(\"CPU usage in %\")\n",
    "    #plt.ylim((0,5))\n",
    "    plt.savefig(outpathCPU + server + \"_\" + str(run) + \".pdf\")\n",
    "    plt.savefig(outpathCPU + server + \"_\" + str(run) + \".jpg\", dpi = 300)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    for k in data:\n",
    "        mem = data[k][\"mem\"]\n",
    "        running = data[k][\"running\"]\n",
    "        plt.plot(running, mem, label = data[k][\"name\"][:40])\n",
    "    plt.ylabel(\"memory usage in %\")\n",
    "    plt.legend()   \n",
    "    #plt.ylim((0,5))\n",
    "    plt.savefig(outpathMem + server + \"_\" + str(run) + \".pdf\")\n",
    "    plt.savefig(outpathMem + server + \"_\" + str(run) + \".jpg\", dpi = 300)\n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f689c19ed84f4c83d75d45583d846a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f229c76f790447fa5c68ddcea4a5c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4259bbb8eb624c05ba86b1074160cb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "runs = [x for x in os.listdir(path)]\n",
    "\n",
    "for run in runs:\n",
    "    p = path + run + os.path.sep + \"logs\" + os.path.sep + \"usage\" + os.path.sep\n",
    "    servers = os.listdir(p)\n",
    "    for server in tqdm(servers):\n",
    "        file = open(p + server + os.path.sep + \"ps.log\", 'r') \n",
    "        lines = file.readlines() \n",
    "        extractUsage(lines, server, run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responsibilities\n",
    "\n",
    "shows already the server ID not kafka ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mRUN:0\u001b[0m\n",
      "t4\n",
      "{0: {'leader': 'server7', 'replicas': {'server7', 'server5', 'server4'}, 'isrs': {'server7', 'server5', 'server4'}}}\n",
      "\n",
      "t5\n",
      "{0: {'leader': 'server4', 'replicas': {'server7', 'server4', 'server3'}, 'isrs': {'server7', 'server4', 'server3'}}}\n",
      "\n",
      "t4_filtered\n",
      "{0: {'leader': 'server4', 'replicas': {'server1', 'server5', 'server4'}, 'isrs': {'server1', 'server5', 'server4'}}}\n",
      "\n",
      "t2_filtered\n",
      "{0: {'leader': 'server5', 'replicas': {'server5', 'server2', 'server4'}, 'isrs': {'server5', 'server2', 'server4'}}}\n",
      "\n",
      "t7_warnings\n",
      "{0: {'leader': 'server6', 'replicas': {'server6', 'server2', 'server4'}, 'isrs': {'server6', 'server2', 'server4'}}}\n",
      "\n",
      "t1_filtered\n",
      "{0: {'leader': 'server5', 'replicas': {'server5', 'server2', 'server6'}, 'isrs': {'server5', 'server2', 'server6'}}}\n",
      "\n",
      "t3\n",
      "{0: {'leader': 'server5', 'replicas': {'server7', 'server5', 'server3'}, 'isrs': {'server7', 'server5', 'server3'}}}\n",
      "\n",
      "t6\n",
      "{0: {'leader': 'server4', 'replicas': {'server1', 'server5', 'server4'}, 'isrs': {'server1', 'server5', 'server4'}}}\n",
      "\n",
      "t6_filtered\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server7', 'server3'}, 'isrs': {'server1', 'server7', 'server3'}}}\n",
      "\n",
      "t5_filtered\n",
      "{0: {'leader': 'server2', 'replicas': {'server6', 'server2', 'server3'}, 'isrs': {'server6', 'server2', 'server3'}}}\n",
      "\n",
      "t7_filtered\n",
      "{0: {'leader': 'server4', 'replicas': {'server6', 'server4', 'server3'}, 'isrs': {'server6', 'server4', 'server3'}}}\n",
      "\n",
      "__consumer_offsets\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server6'}, 'isrs': {'server1', 'server6'}}, 1: {'leader': 'server4', 'replicas': {'server1', 'server4'}, 'isrs': {'server1', 'server4'}}}\n",
      "\n",
      "t2\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server6', 'server3'}, 'isrs': {'server1', 'server6', 'server3'}}}\n",
      "\n",
      "t7\n",
      "{0: {'leader': 'server7', 'replicas': {'server7', 'server2', 'server4'}, 'isrs': {'server7', 'server2', 'server4'}}}\n",
      "\n",
      "t1_warnings\n",
      "{0: {'leader': 'server7', 'replicas': {'server7', 'server6', 'server3'}, 'isrs': {'server7', 'server6', 'server3'}}}\n",
      "\n",
      "t6_warnings\n",
      "{0: {'leader': 'server5', 'replicas': {'server5', 'server2', 'server6'}, 'isrs': {'server5', 'server2', 'server6'}}}\n",
      "\n",
      "t2_warnings\n",
      "{0: {'leader': 'server6', 'replicas': {'server7', 'server6', 'server3'}, 'isrs': {'server7', 'server6', 'server3'}}}\n",
      "\n",
      "t4_warnings\n",
      "{0: {'leader': 'server5', 'replicas': {'server5', 'server2', 'server4'}, 'isrs': {'server5', 'server2', 'server4'}}}\n",
      "\n",
      "t3_filtered\n",
      "{0: {'leader': 'server5', 'replicas': {'server1', 'server5', 'server4'}, 'isrs': {'server1', 'server5', 'server4'}}}\n",
      "\n",
      "t1\n",
      "{0: {'leader': 'server4', 'replicas': {'server7', 'server4', 'server3'}, 'isrs': {'server7', 'server4', 'server3'}}}\n",
      "\n",
      "t5_warnings\n",
      "{0: {'leader': 'server4', 'replicas': {'server5', 'server2', 'server4'}, 'isrs': {'server5', 'server2', 'server4'}}}\n",
      "\n",
      "t3_warnings\n",
      "{0: {'leader': 'server5', 'replicas': {'server1', 'server5', 'server7'}, 'isrs': {'server1', 'server5', 'server7'}}}\n",
      "\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "analyst-0\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "analyst-1\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "analyst-2\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "analyst-3\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "analyst-4\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "analyst-5\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "analyst-6\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "filter-0\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "filter-1\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "filter-2\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "filter-3\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "filter-4\n",
      "{'state': 'Running', 'server': 'server10'}\n",
      "\n",
      "filter-5\n",
      "{'state': 'Running', 'server': 'server9'}\n",
      "\n",
      "filter-6\n",
      "{'state': 'Running', 'server': 'server8'}\n",
      "\n",
      "kafka-0\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "kafka-1\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "kafka-2\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "kafka-3\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "kafka-4\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "kafka-5\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "kafka-6\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "producer-6rd6v\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "producer-bz2fj\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "producer-ffv8x\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "producer-l24bb\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "producer-nv6wc\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "producer-z29gj\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "producer-zvrj2\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "zoo-0\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "zoo-1\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "zoo-2\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "\u001b[34mRUN:1\u001b[0m\n",
      "t4\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server5', 'server3'}, 'isrs': {'server1', 'server5', 'server3'}}}\n",
      "\n",
      "t5\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server5', 'server3'}, 'isrs': {'server1', 'server5', 'server3'}}}\n",
      "\n",
      "t4_filtered\n",
      "{0: {'leader': 'server7', 'replicas': {'server7', 'server6', 'server4'}, 'isrs': {'server7', 'server6', 'server4'}}}\n",
      "\n",
      "t2_filtered\n",
      "{0: {'leader': 'server6', 'replicas': {'server1', 'server6', 'server2'}, 'isrs': {'server1', 'server6', 'server2'}}}\n",
      "\n",
      "t7_warnings\n",
      "{0: {'leader': 'server5', 'replicas': {'server5', 'server4', 'server6'}, 'isrs': {'server5', 'server4', 'server6'}}}\n",
      "\n",
      "t1_filtered\n",
      "{0: {'leader': 'server6', 'replicas': {'server1', 'server6', 'server2'}, 'isrs': {'server1', 'server6', 'server2'}}}\n",
      "\n",
      "t3\n",
      "{0: {'leader': 'server3', 'replicas': {'server7', 'server5', 'server3'}, 'isrs': {'server7', 'server5', 'server3'}}}\n",
      "\n",
      "t6\n",
      "{0: {'leader': 'server5', 'replicas': {'server7', 'server5', 'server3'}, 'isrs': {'server7', 'server5', 'server3'}}}\n",
      "\n",
      "t6_filtered\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server5', 'server7'}, 'isrs': {'server1', 'server5', 'server7'}}}\n",
      "\n",
      "t5_filtered\n",
      "{0: {'leader': 'server7', 'replicas': {'server7', 'server5', 'server3'}, 'isrs': {'server7', 'server5', 'server3'}}}\n",
      "\n",
      "t7_filtered\n",
      "{0: {'leader': 'server2', 'replicas': {'server1', 'server2', 'server3'}, 'isrs': {'server1', 'server2', 'server3'}}}\n",
      "\n",
      "__consumer_offsets\n",
      "{0: {'leader': 'server2', 'replicas': {'server7', 'server2'}, 'isrs': {'server7', 'server2'}}, 1: {'leader': 'server5', 'replicas': {'server5', 'server2'}, 'isrs': {'server5', 'server2'}}}\n",
      "\n",
      "t2\n",
      "{0: {'leader': 'server6', 'replicas': {'server1', 'server6', 'server2'}, 'isrs': {'server1', 'server6', 'server2'}}}\n",
      "\n",
      "t7\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server2', 'server3'}, 'isrs': {'server1', 'server2', 'server3'}}}\n",
      "\n",
      "t1_warnings\n",
      "{0: {'leader': 'server7', 'replicas': {'server1', 'server2', 'server7'}, 'isrs': {'server1', 'server2', 'server7'}}}\n",
      "\n",
      "t6_warnings\n",
      "{0: {'leader': 'server6', 'replicas': {'server1', 'server6', 'server2'}, 'isrs': {'server1', 'server6', 'server2'}}}\n",
      "\n",
      "t2_warnings\n",
      "{0: {'leader': 'server3', 'replicas': {'server7', 'server5', 'server3'}, 'isrs': {'server7', 'server5', 'server3'}}}\n",
      "\n",
      "t4_warnings\n",
      "{0: {'leader': 'server2', 'replicas': {'server1', 'server2', 'server3'}, 'isrs': {'server1', 'server2', 'server3'}}}\n",
      "\n",
      "t3_filtered\n",
      "{0: {'leader': 'server2', 'replicas': {'server1', 'server2', 'server3'}, 'isrs': {'server1', 'server2', 'server3'}}}\n",
      "\n",
      "t1\n",
      "{0: {'leader': 'server4', 'replicas': {'server7', 'server5', 'server4'}, 'isrs': {'server7', 'server5', 'server4'}}}\n",
      "\n",
      "t5_warnings\n",
      "{0: {'leader': 'server6', 'replicas': {'server5', 'server6', 'server3'}, 'isrs': {'server5', 'server6', 'server3'}}}\n",
      "\n",
      "t3_warnings\n",
      "{0: {'leader': 'server2', 'replicas': {'server5', 'server2', 'server3'}, 'isrs': {'server5', 'server2', 'server3'}}}\n",
      "\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "analyst-0\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "analyst-1\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "analyst-2\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "analyst-3\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "analyst-4\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "analyst-5\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "analyst-6\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "filter-0\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "filter-1\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "filter-2\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "filter-3\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "filter-4\n",
      "{'state': 'Running', 'server': 'server10'}\n",
      "\n",
      "filter-5\n",
      "{'state': 'Running', 'server': 'server9'}\n",
      "\n",
      "filter-6\n",
      "{'state': 'Running', 'server': 'server8'}\n",
      "\n",
      "kafka-0\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "kafka-1\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "kafka-2\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "kafka-3\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "kafka-4\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "kafka-5\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "kafka-6\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "producer-6qlmb\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "producer-lvkzg\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "producer-pflw4\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "producer-pvwkr\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "producer-q2q86\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "producer-qnfch\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "producer-s5txw\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "zoo-0\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "zoo-1\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "zoo-2\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "\u001b[34mRUN:2\u001b[0m\n",
      "t4\n",
      "{0: {'leader': 'server3', 'replicas': {'server7', 'server4', 'server3'}, 'isrs': {'server7', 'server4', 'server3'}}}\n",
      "\n",
      "t5\n",
      "{0: {'leader': 'server5', 'replicas': {'server7', 'server5', 'server4'}, 'isrs': {'server7', 'server5', 'server4'}}}\n",
      "\n",
      "t4_filtered\n",
      "{0: {'leader': 'server7', 'replicas': {'server7', 'server6', 'server4'}, 'isrs': {'server7', 'server6', 'server4'}}}\n",
      "\n",
      "t2_filtered\n",
      "{0: {'leader': 'server7', 'replicas': {'server7', 'server5', 'server3'}, 'isrs': {'server7', 'server5', 'server3'}}}\n",
      "\n",
      "t7_warnings\n",
      "{0: {'leader': 'server3', 'replicas': {'server7', 'server4', 'server3'}, 'isrs': {'server7', 'server4', 'server3'}}}\n",
      "\n",
      "t1_filtered\n",
      "{0: {'leader': 'server4', 'replicas': {'server7', 'server6', 'server4'}, 'isrs': {'server7', 'server6', 'server4'}}}\n",
      "\n",
      "t3\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server5', 'server3'}, 'isrs': {'server1', 'server5', 'server3'}}}\n",
      "\n",
      "t6\n",
      "{0: {'leader': 'server6', 'replicas': {'server7', 'server6', 'server4'}, 'isrs': {'server7', 'server6', 'server4'}}}\n",
      "\n",
      "t6_filtered\n",
      "{0: {'leader': 'server4', 'replicas': {'server5', 'server4', 'server3'}, 'isrs': {'server5', 'server4', 'server3'}}}\n",
      "\n",
      "t5_filtered\n",
      "{0: {'leader': 'server1', 'replicas': {'server1', 'server6', 'server4'}, 'isrs': {'server1', 'server6', 'server4'}}}\n",
      "\n",
      "t7_filtered\n",
      "{0: {'leader': 'server5', 'replicas': {'server5', 'server2', 'server3'}, 'isrs': {'server5', 'server2', 'server3'}}}\n",
      "\n",
      "__consumer_offsets\n",
      "{0: {'leader': 'server6', 'replicas': {'server1', 'server6'}, 'isrs': {'server1', 'server6'}}, 1: {'leader': 'server4', 'replicas': {'server7', 'server4'}, 'isrs': {'server7', 'server4'}}}\n",
      "\n",
      "t2\n",
      "{0: {'leader': 'server5', 'replicas': {'server5', 'server4', 'server6'}, 'isrs': {'server5', 'server4', 'server6'}}}\n",
      "\n",
      "t7\n",
      "{0: {'leader': 'server6', 'replicas': {'server1', 'server6', 'server4'}, 'isrs': {'server1', 'server6', 'server4'}}}\n",
      "\n",
      "t1_warnings\n",
      "{0: {'leader': 'server1', 'replicas': {'server7', 'server1', 'server4'}, 'isrs': {'server7', 'server1', 'server4'}}}\n",
      "\n",
      "t6_warnings\n",
      "{0: {'leader': 'server4', 'replicas': {'server7', 'server2', 'server4'}, 'isrs': {'server7', 'server2', 'server4'}}}\n",
      "\n",
      "t2_warnings\n",
      "{0: {'leader': 'server2', 'replicas': {'server7', 'server2', 'server4'}, 'isrs': {'server7', 'server2', 'server4'}}}\n",
      "\n",
      "t4_warnings\n",
      "{0: {'leader': 'server5', 'replicas': {'server1', 'server5', 'server6'}, 'isrs': {'server1', 'server5', 'server6'}}}\n",
      "\n",
      "t3_filtered\n",
      "{0: {'leader': 'server2', 'replicas': {'server5', 'server2', 'server3'}, 'isrs': {'server5', 'server2', 'server3'}}}\n",
      "\n",
      "t1\n",
      "{0: {'leader': 'server1', 'replicas': {'server7', 'server1', 'server2'}, 'isrs': {'server7', 'server1', 'server2'}}}\n",
      "\n",
      "t5_warnings\n",
      "{0: {'leader': 'server6', 'replicas': {'server7', 'server6', 'server4'}, 'isrs': {'server7', 'server6', 'server4'}}}\n",
      "\n",
      "t3_warnings\n",
      "{0: {'leader': 'server4', 'replicas': {'server5', 'server2', 'server4'}, 'isrs': {'server5', 'server2', 'server4'}}}\n",
      "\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "analyst-0\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "analyst-1\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "analyst-2\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "analyst-3\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "analyst-4\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "analyst-5\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "analyst-6\n",
      "{'state': 'Running', 'server': 'server10'}\n",
      "\n",
      "filter-0\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "filter-1\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "filter-2\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "filter-3\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "filter-4\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "filter-5\n",
      "{'state': 'Running', 'server': 'server9'}\n",
      "\n",
      "filter-6\n",
      "{'state': 'Running', 'server': 'server8'}\n",
      "\n",
      "kafka-0\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "kafka-1\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "kafka-2\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "kafka-3\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "kafka-4\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "kafka-5\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "kafka-6\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "producer-2qmxp\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "producer-4kjs5\n",
      "{'state': 'Running', 'server': 'server7'}\n",
      "\n",
      "producer-7pgq6\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "producer-kbw7n\n",
      "{'state': 'Running', 'server': 'server5'}\n",
      "\n",
      "producer-pbn94\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "producer-v8fr5\n",
      "{'state': 'Running', 'server': 'server2'}\n",
      "\n",
      "producer-xz72f\n",
      "{'state': 'Running', 'server': 'server3'}\n",
      "\n",
      "zoo-0\n",
      "{'state': 'Running', 'server': 'server1'}\n",
      "\n",
      "zoo-1\n",
      "{'state': 'Running', 'server': 'server6'}\n",
      "\n",
      "zoo-2\n",
      "{'state': 'Running', 'server': 'server4'}\n",
      "\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "def addToData(data, topic, current, seconds):\n",
    "    #empty\n",
    "    if not current:\n",
    "        return data\n",
    "    \n",
    "    if topic in data:\n",
    "        cd = data[topic]\n",
    "        if cd[\"data\"][-1] != current:\n",
    "            cd[\"data\"].append(current)\n",
    "            cd[\"time\"].append(seconds)\n",
    "    else:\n",
    "        data[topic] = {\n",
    "            \"data\" : [current],\n",
    "            \"time\" : [seconds]\n",
    "        }\n",
    "    \n",
    "    return data\n",
    "\n",
    "def showDiff(data):\n",
    "    for t in data:\n",
    "        print(t)\n",
    "        print(data[t][\"data\"][0]) \n",
    "        if len(data[t][\"data\"]) > 1:\n",
    "            ld = data[t][\"data\"][0]\n",
    "            for x in range(1, len(data[t][\"data\"])):\n",
    "                cd = data[t][\"data\"][x]                \n",
    "                print(\"\\x1b[31m\" + str(list(dictdiffer.diff(ld,cd))) + \"\\x1b[0m\")\n",
    "                print(\"Minute %.1f\" %(data[t][\"time\"][x] / 60))\n",
    "                ld = cd\n",
    "        print()\n",
    "        \n",
    "def replaceKafkaWithNode(c, pods, second):\n",
    "    result = []\n",
    "    for x in c:\n",
    "        d = pods[\"kafka-\" + str(x)]\n",
    "        index = 0\n",
    "        for y in range(len(d[\"time\"])):\n",
    "            if(d[\"time\"][y] > second):\n",
    "                break\n",
    "            index = y\n",
    "        result.append(d[\"data\"][index][\"server\"])\n",
    "    return set(result)\n",
    "\n",
    "def extractResponsibilities(lines):\n",
    "    \n",
    "    trial = 0\n",
    "    seconds = 0\n",
    "    topic = None\n",
    "    partitions = None\n",
    "    kafka = True\n",
    "    \n",
    "    data = {}\n",
    "    pods = {}\n",
    "    \n",
    "    current = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        split = list(filter(lambda x : len(x) > 0, line.split(\" \")))\n",
    "        if(line.startswith(\"Trial \")):\n",
    "            kafka = True\n",
    "            trial = int(split[1])\n",
    "            seconds = int(split[3])\n",
    "            current = {}\n",
    "        elif(line.startswith(\"  topic \\\"\")):\n",
    "            data = addToData(data, topic, current, seconds)\n",
    "            topic = split[1][1:-1]\n",
    "            partitions = int(split[3])\n",
    "            current = {}\n",
    "        elif(line.startswith(\"    partition \")):\n",
    "            partition = int(split[1][:-1]) \n",
    "            leader =  int(split[3][:-1]) \n",
    "            replicas = set([int(x) for x in split[5][:-1].split(\",\")])\n",
    "            isrs = set([int(x) for x in split[7][:-1].split(\",\")])\n",
    "            current[partition] = {\n",
    "                \"leader\" : leader,\n",
    "                \"replicas\" : replicas,\n",
    "                \"isrs\" : isrs\n",
    "            }\n",
    "        elif(line.startswith(\"pod \\\"debug\")):\n",
    "            data = addToData(data, topic, current, seconds)\n",
    "        elif(line.startswith(\"NAME\")):\n",
    "            kafka = False\n",
    "        elif(not kafka):\n",
    "            if(line.startswith((\"analyst\", \"filter\", \"kafka\", \"producer\", \"zoo\"))):\n",
    "                pod = split[0]\n",
    "                state = split[1]\n",
    "                server = split[2][:-1]\n",
    "                \n",
    "                current = {\n",
    "                    \"state\" : state,\n",
    "                    \"server\": server\n",
    "                }\n",
    "                \n",
    "                if pod in pods:\n",
    "                    if pods[pod][\"data\"][-1] != current:\n",
    "                        pods[pod][\"data\"].append(current)\n",
    "                        pods[pod][\"time\"].append(seconds)\n",
    "                else:\n",
    "                    pods[pod] = {\n",
    "                        \"data\" : [current],\n",
    "                        \"time\" : [seconds]\n",
    "                    }\n",
    "                \n",
    "            else:\n",
    "                print(\"Error\", line)\n",
    "            \n",
    "    for t in data:\n",
    "        for i in range(len(data[t][\"data\"])):\n",
    "            c = data[t][\"data\"][i]\n",
    "            time = data[t][\"time\"][i]\n",
    "            for partition in c:\n",
    "                \n",
    "                c[partition][\"replicas\"] = replaceKafkaWithNode(c[partition][\"replicas\"], pods, time)\n",
    "                c[partition][\"isrs\"] = replaceKafkaWithNode(c[partition][\"isrs\"], pods, time)\n",
    "                c[partition][\"leader\"] = list(replaceKafkaWithNode([c[partition][\"leader\"]], pods, 0))[0]\n",
    "               \n",
    "    showDiff(data)\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(\"====================================\")\n",
    "        \n",
    "    showDiff(pods)\n",
    "    \n",
    "    for i in range(5):\n",
    "        print(\"====================================\")\n",
    "\n",
    "runs = os.listdir(path)\n",
    "for run in runs:    \n",
    "    print(\"\\x1b[34mRUN:\" + str(run) + \"\\x1b[0m\")\n",
    "    p = path + run + os.path.sep + \"logs\" + os.path.sep + \"responsibilities.log\"\n",
    "    file = open(p, 'r') \n",
    "    lines = file.readlines()\n",
    "    extractResponsibilities(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
