{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Questions\n",
    "\n",
    "- wieso verliere ich Daten zwischen Produced und Filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"~/work/data/test\"\n",
    "topic = \"t18\"\n",
    "full_path = path + \"/\" + topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "produced_df = pandas.read_csv(full_path + \"_produced.csv\")\n",
    "start_df = pandas.read_csv(full_path + \".csv\")\n",
    "filtered_df = pandas.read_csv(full_path + \"_filtered.csv\")\n",
    "warnings_df = pandas.read_csv(full_path + \"_warnings.csv\")\n",
    "modelchange_df = pandas.read_csv(full_path + \"_modelchange.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAvgMedStdMinMaxFromArray(diff):\n",
    "    return np.average(diff), np.median(diff), np.std(diff), np.min(diff), np.max(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information on the time difference between the arival time of records for all 3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produced:\n",
      "Got in average every 5.00 ms new data, with median 5.00, and std = 3.96, further min was 0 and max 393\n",
      "\n",
      "\n",
      "filtered:\n",
      "Got in average every 5.00 ms new data, with median 5.00, and std = 31.76, further min was 0 and max 8001\n",
      "\n",
      "\n",
      "warning:\n",
      "Got in average every 4471.23 ms new data, with median 434.50, and std = 9353.46, further min was 0 and max 40491\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def avgMedStdArivalTime(df, column):\n",
    "    df = df.to_numpy()[:,column].astype(int)\n",
    "    #print(df)\n",
    "    diff = df[1:,]-df[:-1,]\n",
    "    \n",
    "    return extractAvgMedStdMinMaxFromArray(diff)\n",
    "    \n",
    "def getArivalInfos():\n",
    "    text = \"%s:\\nGot in average every %.2f ms new data, with median %.2f, and std = %.2f, further min was %d and max %d\\n\\n\"\n",
    "    print(text %(\"produced\", *avgMedStdArivalTime(produced_df, 3)))\n",
    "    print(text %(\"filtered\", *avgMedStdArivalTime(filtered_df, 0)))\n",
    "    print(text %(\"warning\", *avgMedStdArivalTime(warnings_df, 0)))\n",
    "    \n",
    "getArivalInfos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Produced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long does it take until a produced record is acknowledged by kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced data was received by Kafka after: avg = 0.02 ms; median 0.00 ms; std = 0.25 ms, further min was 0 ms and max 42 ms\n"
     ]
    }
   ],
   "source": [
    "def kafkaAck(df):\n",
    "    ack = df.to_numpy()[:,1].astype(int)\n",
    "    send = df.to_numpy()[:,3].astype(int)\n",
    "    diff = send - ack\n",
    "    \n",
    "    return extractAvgMedStdMinMaxFromArray(diff)\n",
    "    \n",
    "print(\"Produced data was received by Kafka after: avg = %.2f ms; median %.2f ms; std = %.2f ms, further min was %d ms and max %d ms\" %kafkaAck(produced_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check validity of produced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid\n"
     ]
    }
   ],
   "source": [
    "def validate(df):\n",
    "    df = df.to_numpy()\n",
    "    lastRow = df[0]\n",
    "    error = False\n",
    "    for x in df[1:]:\n",
    "        if(np.sum(x >= lastRow) != 4):\n",
    "            error = True\n",
    "            print(\"Error:\")\n",
    "            print(lastRow)\n",
    "            print(x)\n",
    "        if(lastRow[0] + 1 != x[0]):\n",
    "            print(\"Offset %i increased not by 1\" %lastRow[0])\n",
    "            \n",
    "        lastRow = x\n",
    "    if(not error):\n",
    "        print(\"Valid\")\n",
    "        \n",
    "validate(produced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loss produced to filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received records 0x for 91 times; \n"
     ]
    }
   ],
   "source": [
    "def calcDataLoss(df1, df1OffsetColumn, df2, df2OffsetColumn):\n",
    "    df1Offsets = df1.to_numpy()[:,df1OffsetColumn].astype(int)\n",
    "    df2Offsets = df2.to_numpy()[:,df2OffsetColumn].astype(int)\n",
    "    \n",
    "    errors = {}\n",
    "    \n",
    "    for x in df1Offsets:\n",
    "        count = np.sum(df2Offsets == x)\n",
    "        \n",
    "        if(count != 1):\n",
    "            errors[count] = errors.get(count, 0) + 1\n",
    "    \n",
    "    out = \"Received records \"\n",
    "    for k, v in errors.items():\n",
    "        out += \"%ix for %i times; \" %(k,v)\n",
    "    print(out)\n",
    "    \n",
    "calcDataLoss(produced_df, 0, filtered_df, 3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency produced - warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies were detected by Kafka after: avg = 2633.90 ms; median 2026.50 ms; std = 1708.79 ms, further min was 1145 ms and max 7459 ms\n"
     ]
    }
   ],
   "source": [
    "def calcLatencyProduceWarning(modelchange_df, warnings_df, amplitude, periodLength):\n",
    "    m = modelchange_df.to_numpy()\n",
    "    w = warnings_df.to_numpy()\n",
    "    lastChange = m[0]\n",
    "\n",
    "    open = False\n",
    "    s = None\n",
    "    \n",
    "    diff = []\n",
    "    \n",
    "    for x in m:\n",
    "        if x[1] == amplitude and x[2] == periodLength:\n",
    "            open = False\n",
    "            \n",
    "            # search warnings\n",
    "            a = w[:,6] >= lastChange[0]\n",
    "\n",
    "            b = w[:,7] <= x[0]\n",
    "            \n",
    "            inner = np.logical_and(a,b)\n",
    "            \n",
    "            leftOuter = np.logical_and(w[:,6] <= lastChange[0], w[:,7] >= lastChange[0])\n",
    "            rightOuter = np.logical_and(w[:,6] <= x[0], w[:,7] >= x[0])\n",
    "\n",
    "            fullRange = np.logical_or(leftOuter, inner)\n",
    "            fullRange = np.logical_or(fullRange, rightOuter)\n",
    "            \n",
    "            if s is None:\n",
    "                fullRange.astype(int)\n",
    "                s = fullRange\n",
    "            else:\n",
    "                s = np.add(s,fullRange.astype(int))\n",
    "            \n",
    "            matching = w[fullRange]     \n",
    "            \n",
    "            #first recognition\n",
    "            r = min(matching[:,0])\n",
    "            diff.append(r - lastChange[0])\n",
    "            \n",
    "        else:\n",
    "            #skip two changes without a reset\n",
    "            if not open:\n",
    "                lastChange = x\n",
    "            open = True\n",
    "        \n",
    "    if not np.all(s == 1):\n",
    "        print(\"Didn't match all recognized changes! With 0 weren't matched:\")\n",
    "        print(s)\n",
    "        \n",
    "    diff = np.array(diff)\n",
    "    \n",
    "    return extractAvgMedStdMinMaxFromArray(diff)\n",
    "\n",
    "print(\"Anomalies were detected by Kafka after: avg = %.2f ms; median %.2f ms; std = %.2f ms, further min was %d ms and max %d ms\" %calcLatencyProduceWarning(modelchange_df, warnings_df, 3, 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
